# AI Strategy: Page Classification, Curation, and Training (LayoutLMv3)

This document is the “source of truth” for how we store curated data, extract features, build vector indexes, and train a page-level classifier using LayoutLMv3. It is written for implementers and future maintainers.

## Goals

- Page-first labeling: classify each page into a content-derived label (e.g., `Form_1040_SS_P1`).
- Scalable curation: easily add more pages for an existing label; keep provenance and reproducibility.
- Training-ready data: store text + layout + image so LayoutLMv3 training does not depend on the original PDFs.
- Fast suggestion + dedupe: maintain a vector index for “find similar pages” and near-duplicate detection.

## Data Model (Per Page)

Required fields

- Identity
  - `id`: `${document}#${page}`
  - `document`, `page` (1-based), `source_json`, `source` (e.g., UltraTax)
  - `added_at`, `added_by`, `dataset_version`
- Labels
  - `label` (current editable target)
  - `auto_label` (default generated by app)
  - `updated_label` (bool: user changed label)
  - `base_label` (prefix before `_P#`), `page_in_form` (int), `multipage` (bool)
  - `raw_label` (bookmark title)
- Image
  - `image_path` (rendered PNG)
  - `image_size`: `{width_px, height_px, dpi}`
- Text + Layout (LayoutLMv3 inputs)
  - `words`: `[str, ...]` (reading order)
  - `boxes`: `[[x0,y0,x1,y1], ...]` in pixels
  - `boxes_norm`: `[[x0,y0,x1,y1], ...]` normalized to 0–1000 ints
  - `page_size_pts`: `{width, height}` (PDF units)
  - `text_source`: `pdf_text | ocr` ; `ocr_engine` if used; `text_len`

Optional fields

- `header_lines[]`, `footer_lines[]`
- Hashes: `phash` (image), `text_simhash` (text), `md5_image`, `md5_text`
- `split`: `train|val|test`
- `notes`, `tags[]`

## Storage Layout

Repository-relative folders

```
dataset/
  index/                 # JSONL shards (append-only)
    v1.jsonl
    v1_additions_2025-10-11.jsonl
  images/<base_label>/   # rendered page images
    <doc>_<page>.png
  features/              # optional cached tokens/boxes
  embeddings/            # CLIP or page embeddings (.parquet or .npy)
  faiss/                 # FAISS index + id map
  manifests/
    v1.json              # counts, labels, sources, tool versions
  splits/
    v1_splits.json       # doc-level stratified split definitions
```

Formats

- Primary: JSONL (append-only, easy diffs)
- Secondary: Parquet (analytics at scale)
- Images: PNG at 224–512 DPI, per label subfolder

## Pipelines

1) Ingest (append-only, idempotent)

- Input: enhanced JSON from the app (contains `label`, `auto_label`, `updated_label`, `base_label`, `page_in_form`, `multipage`, `raw_label`).
- For each page:
  - Render image (PyMuPDF/fitz) to PNG (e.g., 300 DPI)
  - Extract words + boxes with pdfplumber or PyMuPDF; OCR fallback (Tesseract/PaddleOCR) when needed
  - Normalize boxes to 0–1000 ints
  - Write JSONL row; copy image into `dataset/images/<base_label>/`

2) Index build (suggestions + dedupe)

- Compute visual embeddings (OpenCLIP ViT-B/32) for page images → store in `embeddings/*.parquet`
- Build FAISS index (HNSW or IVF+Flat/PQ) + `id_map.jsonl` in `dataset/faiss/`
- Optional: text embeddings (`sentence-transformers`) for a second index

3) Training pack (LayoutLMv3)

- Load JSONL rows → read `image`, `words`, `boxes_norm`
- Use HuggingFace `LayoutLMv3Processor` to prepare tensors
- Stratified doc-level split to avoid leakage (persist in `splits/`)
- Save a HuggingFace `datasets` cache or NumPy/Arrow arrays

4) Validation/QA

- Schema checks (Pydantic or JSON Schema): required fields, label pattern, lengths match, boxes within page
- Great Expectations: label coverage, per-label min counts, drift vs previous manifest
- Dedupe checks: `md5_image`, phash distance, text simhash distance thresholds

## Vector Index Details

Why

- Suggest labels (“top-5 similar pages”) to speed up curation
- Detect near-duplicates and reduce noise
- Enable active learning: surface low-confidence/hard examples

What to index

- Visual embeddings (CLIP ViT-B/32) – primary signal
- Optional text embeddings – complementary signal

How

- Store embeddings with an `id` column matching the JSONL rows’ `id`
- Build FAISS index files + `id_map.jsonl`
- Update nightly or incrementally after N new pages

## Modeling Plan

Baselines

- Text TF–IDF (header+body) + Linear SVM/LogReg
- Visual embeddings (CLIP/ResNet) + kNN/LogReg
- Fusion: concatenate text and visual features

Primary model

- LayoutLMv3-base fine-tuned for page classification
  - Inputs: image + words + boxes_norm
  - Target: `label` (or two-head model: `base_label` and `page_in_form`)
  - Training logs in MLflow/W&B; include `dataset_version` in run metadata

Metrics

- Macro-F1 by label; confusion matrix; drift report by day/version

## Versioning & Governance

- Dataset is versioned by immutable manifests (`dataset/manifests/vN.json`)
- JSONL shards are append-only; additions bump a minor version
- Store tool versions and repo commit hash in the manifest
- Use DVC + S3/MinIO for large artifacts if needed

## App Integration (Flask)

- “Add to Curated Dataset” button → run Ingest for selected pages
- “Suggest Labels” → query FAISS index for neighbors and show labels as chips
- Keep `auto_label` vs `label`; mark `updated_label=true` for user edits
- Do not use absolute `page` as a model feature; it’s metadata only

## Open Decisions / Defaults

- DPI for rendering: default 300 dpi (adjust if throughput matters)
- OCR engine: Tesseract for simplicity; PaddleOCR if needed for speed/accuracy
- Storage format: JSONL first, Parquet mirror optional
- Index type: FAISS HNSW (good balance of speed/quality)

## Appendix: Example Record (JSONL)

```json
{
  "id": "1040_US_FED.pdf#27",
  "document": "1040_US_FED.pdf",
  "page": 27,
  "label": "Form_1040_SS_P1",
  "auto_label": "Form_1040_SS_P1",
  "updated_label": false,
  "base_label": "Form_1040_SS",
  "page_in_form": 1,
  "multipage": true,
  "raw_label": "Form 1040-SS",
  "image_path": "dataset/images/Form_1040_SS/1040_US_FED_27.png",
  "image_size": {"width_px": 1700, "height_px": 2200, "dpi": 300},
  "words": ["Form", "1040-SS", "U.S.", "..."],
  "boxes": [[120,85,280,115]],
  "boxes_norm": [[70,39,165,53]],
  "page_size_pts": {"width": 612, "height": 792},
  "text_source": "pdf_text",
  "text_len": 2350,
  "split": "train",
  "curated_by": "user@org",
  "curated_at": "2025-10-11T10:42:00Z",
  "source_json": "Ground_Truth/1040_US_FED_Oct10.json"
}
```

